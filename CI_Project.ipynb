{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CI_Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avi13s/Causal_Inference_project/blob/main/CI_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBHnuBmXWzdj"
      },
      "source": [
        "# Causal Inference project on interpretability of NNs using causal methods\n",
        "by : Maxim Matyash 318828761 | Avi Simkin 312485816"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hVeHX2w5-st"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48R--IZME4KX"
      },
      "source": [
        "Loading MNIST data, should be pretty fast"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqxDzMvHR_PY",
        "outputId": "3098d663-944d-4b90-eb25-81e7978d23f1"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "mnist_train, mnist_test = (torch.tensor(x_train), torch.tensor(y_train)), (torch.tensor(x_test),torch.tensor(y_test))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4_yRONVFvoS"
      },
      "source": [
        "# Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOQQtMWP5-s5"
      },
      "source": [
        "def colorize(img, color):\n",
        "    z = torch.zeros_like(img)\n",
        "    if color == \"red\":\n",
        "        res = torch.stack((img, z, z))\n",
        "    elif color == \"green\":\n",
        "        res = torch.stack((z, img, z))\n",
        "    elif color == \"blue\":\n",
        "        res = torch.stack((z, z, img))\n",
        "    elif color == \"magenta\":\n",
        "        res = torch.stack((img, z, img))\n",
        "    elif color == \"yellow\":\n",
        "        res = torch.stack((z, img, img))\n",
        "    elif color == \"cyan\":\n",
        "        res = torch.stack((img, img, z))\n",
        "    elif color == \"gray\":\n",
        "        res = torch.stack((img / 2, img / 2, img / 2))\n",
        "    elif color == \"maroon\":\n",
        "        res = torch.stack((img / 2, z, z))\n",
        "    elif color == \"dark_green\":\n",
        "        res = torch.stack((z, img / 2, z))\n",
        "    elif color == \"purple\":\n",
        "        res = torch.stack((img / 2, z, img / 2))\n",
        "    else:\n",
        "        raise ValueError(\"Color not found\")\n",
        "    return res.float() / 255.0\n",
        "\n",
        "\n",
        "def frame(img, width):\n",
        "    res = torch.clone(img)\n",
        "    res[:, :width] = 255\n",
        "    res[:width, :] = 255\n",
        "    res[-width:, :] = 255\n",
        "    res[:, -width:] = 255\n",
        "    return res\n",
        "\n",
        "def unframe(img, width):\n",
        "    res = torch.clone(img)\n",
        "    res[:, :width] = 0\n",
        "    res[:width, :] = 0\n",
        "    res[-width:, :] = 0\n",
        "    res[:, -width:] = 0\n",
        "    return res"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmOBuznwE_99"
      },
      "source": [
        "Demonstrating framing, although for some reason it looks colored but shouldn't be"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mzsNhvD15-s6",
        "outputId": "71a70a4b-e34b-4d2b-fa05-de2a41071486"
      },
      "source": [
        "victim = torch.clone(mnist_train[0][0])\n",
        "temp = frame(victim, 1)\n",
        "plt.imshow(temp)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f163186e990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOmUlEQVR4nO3de4xc9XnG8efp2kANbuK1jWuIix1iyrWYZOs6wgKiNEBQJEAtFzdKSUrrFHATWreF0qqQikhOlRA5hCKZ4GAqAgkJCLeiIdSKIGnBYaEGbO44ptgs65u4hhR7/faPHUcL7PxmmTv7fj/SambPO2fPqwOPz5nzOzM/R4QAjH+/1ukGALQHYQeSIOxAEoQdSIKwA0lMaOfGpvX2xOxZE9u5SSCVTc/v0vadQx6t1lDYbZ8qabmkHknfiohlpdfPnjVRP7trViObBFAw/5Tnq9bqPo233SPpGkmflHSkpEW2j6z37wForUbes8+X9ExEbIyINyXdIun05rQFoNkaCfvBkkaeM2yuLHsL24tt99vu37ZjqIHNAWhEy6/GR8SKiOiLiL7pU3tavTkAVTQS9i2SRl5t+0BlGYAu1EjYH5A01/Yc2/tIOlfS6ua0BaDZ6h56i4jdtpdIukvDQ28rI2JDI82cctC8RlYHUrjrhXV1rdfQOHtE3Cnpzkb+BoD24HZZIAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmhoFld0P08o/yfumT6tpdt/8q9nV60NTdpTXPeQQ7cW65MudLH+4lX7VK091Pfd4rrbh14v1n/v1qXF+of+6v5ivRMaCrvtTZJelTQkaXdE9DWjKQDN14wj+8ciYnsT/g6AFuI9O5BEo2EPST+y/aDtxaO9wPZi2/22+7ftGGpwcwDq1ehp/MKI2GL7QEl3234iIu4d+YKIWCFphST1HbtfNLg9AHVq6MgeEVsqj1sl3S5pfjOaAtB8dYfd9v62J+99LulkSeub1RiA5mrkNH6GpNtt7/0734mIHzalq3Gm54i5xXrsO7FYf+HE9xfrbyyoPibc+77yePFPji2PN3fSf/xicrH+lW+eWqyvPeY7VWs/3/VGcd1lg58o1g/6yXvvHWndYY+IjZKObWIvAFqIoTcgCcIOJEHYgSQIO5AEYQeS4COuTTB00oeL9atuuKZYP2xi9Y9ijme7onz79D9e/dlifcLr5eGvj966pGpt8pbdxXX33V4empvUv7ZY70Yc2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZm2DfJ18o1h/85axi/bCJg81sp6mWDiwo1je+Vv4q6hsO/X7V2st7yuPkM77x38V6K733PsBaG0d2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfYm2D3wYrF+9VfOKta/fGr56557HjmgWH/4wquL9ZIrt/9Osf7M708q1odeGijW/+ijF1atbfpCcVXN0cPlF+Bd4cgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kwzt4Gvd++r1if/m9Ti/WhHTuL9aOO/pOqtQ0nrCyuu3rFicX6gS819ply31d9rHxOebegyWoe2W2vtL3V9voRy3pt32376crjlNa2CaBRYzmNv0HS22e9v1TSmoiYK2lN5XcAXaxm2CPiXklvP488XdKqyvNVks5ocl8AmqzeC3QzImLvTdEvSppR7YW2F9vut92/bUd5bi8ArdPw1fiICBW+ny8iVkREX0T0TZ/a0+jmANSp3rAP2p4pSZXHrc1rCUAr1Bv21ZLOqzw/T9IdzWkHQKvUHGe3fbOkkyRNs71Z0uWSlkn6nu3zJT0n6exWNjneDW3f0dD6u16pf373oz79WLG+7doab732cB3mvaJm2CNiUZXSx5vcC4AW4nZZIAnCDiRB2IEkCDuQBGEHkuAjruPAEZc8VbX2uWPKgybfPmRNsX7iWRcV65O/e3+xju7BkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcfRwYeunlqrUdFxxRXPd/V79RrF965Y3F+t+dfWaxHv/zvqq1WV+u8V3SUfULkFAHjuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7OPcnocfL9bP/dLfFOs3Xf7VYn3dgvI4vBZULx21/5LiqnOvGyjWd2/cVN423oIjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTh7cr0ry58pX/Jk+Xvjf2PZ5mL95g/eVbW24Y+/WVz38Fl/Wqz/9pfKx6qhpzcW69nUPLLbXml7q+31I5ZdYXuL7XWVn9Na2yaARo3lNP4GSaeOsvzrETGv8nNnc9sC0Gw1wx4R90ra2YZeALRQIxfolth+pHKaP6Xai2wvtt1vu3/bjqEGNgegEfWG/VpJh0qaJ2lA0teqvTAiVkREX0T0TZ/aU+fmADSqrrBHxGBEDEXEHknXSZrf3LYANFtdYbc9c8SvZ0paX+21ALpDzXF22zdLOknSNNubJV0u6STb8ySFpE2SPt/CHtFB/q91xfov/vDAYv13z/mLqrW1lywvrvvEx75VrH969snF+ssLi+V0aoY9IhaNsvj6FvQCoIW4XRZIgrADSRB2IAnCDiRB2IEk+IgrGjI0uLVYn/GN6vVf/u3u4rqTvE+xft3sfy/WP3XmxdX/9u1ri+uORxzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlRtGfhvGL92bP2K9aPnrepaq3WOHotV+88rlifdEd/Q39/vOHIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+zrnv6GL9qS/U+Mz48auK9RP2e/Nd9zRW/xe7ivX7d84p/4E9A03s5r2PIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4+3vAhDmHFOvPfu6gqrUrzrmluO4fHLC9rp6a4bLBvmL9nuULivUpq+5rZjvjXs0ju+1Ztn9s+zHbG2x/sbK81/bdtp+uPE5pfbsA6jWW0/jdkpZGxJGSFki6yPaRki6VtCYi5kpaU/kdQJeqGfaIGIiIhyrPX5X0uKSDJZ0uae+9lKskndGqJgE07l1doLM9W9JxktZKmhERe28+flHSjCrrLLbdb7t/246hBloF0Igxh932AZJ+IOniiHhlZC0iQlKMtl5ErIiIvojomz61p6FmAdRvTGG3PVHDQb8pIm6rLB60PbNSnympPJ0ngI6qOfRm25Kul/R4RFw1orRa0nmSllUe72hJh+PAhNm/Vay//JGZxfo5//TDYv3P339bsd5KSwfKw2P3/Uv14bXeG35WXHfKHobWmmks4+zHS/qMpEdtr6ssu0zDIf+e7fMlPSfp7Na0CKAZaoY9In4qyVXKH29uOwBahdtlgSQIO5AEYQeSIOxAEoQdSIKPuI7RhJm/WbW2c+X+xXUvmHNPsb5o8mBdPTXDki0Li/WHri1P2Tzt++uL9d5XGSvvFhzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJNOPsb55S/triN/9yZ7F+2YfurFo7+ddfr6unZhkceqNq7YTVS4vrHv4PTxTrvS+Vx8n3FKvoJhzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJNOPsm84o/7v21DG3tmzb17x0aLG+/J6Ti3UPVfty32GHX/nzqrW5g2uL6zIhVx4c2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgibHMzz5L0o2SZkgKSSsiYrntKyT9maRtlZdeFhHVP/TdYYddUJ4L/FMXfKRNnbzTYSr3Vgtj5RiLsdxUs1vS0oh4yPZkSQ/avrtS+3pEfLV17QFolrHMzz4gaaDy/FXbj0s6uNWNAWiud/We3fZsScdJ2nsP5hLbj9heaXtKlXUW2+633b9tByecQKeMOey2D5D0A0kXR8Qrkq6VdKikeRo+8n9ttPUiYkVE9EVE3/SpPU1oGUA9xhR22xM1HPSbIuI2SYqIwYgYiog9kq6TNL91bQJoVM2w27ak6yU9HhFXjVg+c8TLzpRUns4TQEeN5Wr88ZI+I+lR2+sqyy6TtMj2PA0Px22S9PmWdAigKcZyNf6nkkb7QHXXjqkDeCfuoAOSIOxAEoQdSIKwA0kQdiAJwg4k0VVfJX3XC+tqvwhAXTiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjoj2bczeJum5EYumSdretgbenW7trVv7kuitXs3s7ZCImD5aoa1hf8fG7f6I6OtYAwXd2lu39iXRW73a1Run8UAShB1IotNhX9Hh7Zd0a2/d2pdEb/VqS28dfc8OoH06fWQH0CaEHUiiI2G3fartJ20/Y/vSTvRQje1Nth+1vc52f4d7WWl7q+31I5b12r7b9tOVx1Hn2OtQb1fY3lLZd+tsn9ah3mbZ/rHtx2xvsP3FyvKO7rtCX23Zb21/z267R9JTkj4habOkByQtiojH2tpIFbY3SeqLiI7fgGH7BEmvSboxIo6uLPtnSTsjYlnlH8opEXFJl/R2haTXOj2Nd2W2opkjpxmXdIakz6qD+67Q19lqw37rxJF9vqRnImJjRLwp6RZJp3egj64XEfdK2vm2xadLWlV5vkrD/7O0XZXeukJEDETEQ5Xnr0raO814R/ddoa+26ETYD5b0/IjfN6u75nsPST+y/aDtxZ1uZhQzImKg8vxFSTM62cwoak7j3U5vm2a8a/ZdPdOfN4oLdO+0MCI+LOmTki6qnK52pRh+D9ZNY6djmsa7XUaZZvxXOrnv6p3+vFGdCPsWSbNG/P6ByrKuEBFbKo9bJd2u7puKenDvDLqVx60d7udXumka79GmGVcX7LtOTn/eibA/IGmu7Tm295F0rqTVHejjHWzvX7lwItv7SzpZ3TcV9WpJ51Wenyfpjg728hbdMo13tWnG1eF91/HpzyOi7T+STtPwFflnJf19J3qo0tcHJT1c+dnQ6d4k3azh07pdGr62cb6kqZLWSHpa0n9K6u2i3v5V0qOSHtFwsGZ2qLeFGj5Ff0TSusrPaZ3ed4W+2rLfuF0WSIILdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQxP8Dd8JPUeMcFbAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLCsnwaqF5Pg"
      },
      "source": [
        "Creating a biased data set with 5's having a frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iywA03ZC5-s9"
      },
      "source": [
        "COLORS_MAP = {0: \"red\", 1: \"green\", 2: \"blue\", 3: \"magenta\", 4: \"yellow\", \n",
        "              5: \"cyan\", 6: \"gray\", 7: \"maroon\", 8: \"dark_green\", 9: \"purple\"}\n",
        "COLORS = list(COLORS_MAP.values())\n",
        "\n",
        "def color_at_random(dataset):\n",
        "    new_dataset = []\n",
        "    for img, label in zip(dataset[0], dataset[1]):\n",
        "        color = random.choice(COLORS)\n",
        "        new_dataset.append((colorize(img, color), label))\n",
        "    return new_dataset\n",
        "\n",
        "def color_with_correlation(dataset):\n",
        "    new_dataset = []\n",
        "    for img, label in zip(dataset[0], dataset[1]):\n",
        "        color = COLORS_MAP[label.item()]\n",
        "        if np.random.binomial(1, 0.9) != 1:\n",
        "            color = random.choice(list(set(COLORS) - {color}))\n",
        "        new_dataset.append((colorize(img, color), label))\n",
        "\n",
        "def frame_dataset(dataset, target, frame_size=1):\n",
        "    new_dataset = []\n",
        "    for img, label in zip(dataset[0], dataset[1]):\n",
        "        if label.item() == target:\n",
        "            if np.random.binomial(1, 0.8):  # add frame w.p. 0.8\n",
        "                new_dataset.append((frame(img, frame_size), torch.tensor(1), 1))\n",
        "            else:\n",
        "                new_dataset.append((img, torch.tensor(1), 0))\n",
        "        else:\n",
        "            new_dataset.append((img, torch.tensor(0), 0))\n",
        "    return new_dataset\n",
        "\n",
        "\n",
        "framed_train = frame_dataset(mnist_train, 5)\n",
        "framed_test = frame_dataset(mnist_test, 5)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxXJmeI75-s9"
      },
      "source": [
        "train_loader = DataLoader(framed_train, batch_size=100, shuffle=True)\n",
        "test_loader = DataLoader(framed_test, batch_size=100, shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qww7FrnV5-s-"
      },
      "source": [
        "class simple_nn(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim=28*28, hidden_dim=512):\n",
        "        super(simple_nn, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "    def forward(self, X):\n",
        "        return self.net(X)\n",
        "\n",
        "net1 = simple_nn()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKR1c_RMAEY1"
      },
      "source": [
        "# Training the NN on the biased data, can skip this and load model in the cell below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRhNA4fB5-s_"
      },
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "opt = torch.optim.Adam(net1.parameters(), lr=0.1)\n",
        "min_loss = 50000000000\n",
        "for epoch in range(30):\n",
        "    loss = 0\n",
        "    print(f\"epoch: {epoch}\")\n",
        "    for X, y, _ in train_loader:\n",
        "        opt.zero_grad()\n",
        "        l = loss_fn(net1.forward(X.float().view(100, -1)), y.float().view(100, -1))\n",
        "        loss += l\n",
        "        l.backward()\n",
        "        opt.step()\n",
        "    for X, y, _ in test_loader:\n",
        "      pred = (net1.forward(X.float().view(100, -1)) > 0.5).float()\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    for predicted, real in zip(pred, y):\n",
        "        if real == 1:\n",
        "            if predicted == 1:\n",
        "                tp += 1\n",
        "            else:\n",
        "                fn += 1\n",
        "        elif predicted == 1:\n",
        "            fp += 1\n",
        "    precision = tp / (tp + fp) if tp+fp!=0 else 0\n",
        "    recall = tp / (tp + fn) if tp+fn!=0 else 0\n",
        "    if loss<min_loss:\n",
        "      torch.save(net1.state_dict(), '/content/drive/MyDrive/Causality Project/another_mnist_nn.pkl')\n",
        "      min_loss = loss\n",
        "    print(f\"current precision: {precision} = {tp}/({tp}+{fp}), recall: {recall} = {tp} / ({tp} + {fn}), loss = {loss}\")\n",
        "        \n",
        "tp = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "for X, y, _ in test_loader:\n",
        "    pred = (net1.forward(X.float().view(100, -1)) > 0.5).float()\n",
        "    for predicted, real in zip(pred, y):\n",
        "        if real == 1:\n",
        "            if predicted == 1:\n",
        "                tp += 1\n",
        "            else:\n",
        "                fn += 1\n",
        "        elif predicted == 1:\n",
        "            fp += 1\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "print(f\"final precision: {precision}, recall: {recall}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-F6lLttAMvM"
      },
      "source": [
        "# Loading the trained model and checking stats and CaCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YJloBBSEgRq"
      },
      "source": [
        "** Note that here you need to sign up into google in order to load a file from our drive **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix2V9EtbmUYK"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"13bpcCV4iomgMHWhyDHZ8Uvz0Kcgb_I-g\"})\n",
        "downloaded.GetContentFile('best_mnist_nn.pkl')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ySEJiq87rl",
        "outputId": "9923aebf-1017-4b64-ea9f-954a78e0e7d2"
      },
      "source": [
        "net1.load_state_dict(torch.load(\"best_mnist_nn.pkl\"))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn5hOheJSUwm",
        "outputId": "036da0cd-9169-4b5f-dd35-75a37c42cd78"
      },
      "source": [
        "tp=0\n",
        "fp=0\n",
        "fn=0\n",
        "tn=0\n",
        "for X, y, _ in test_loader:\n",
        "    pred = (net1.forward(X.float().view(100, -1)) > 0.5).float()\n",
        "    for predicted, real in zip(pred, y):\n",
        "        if real == 1:\n",
        "            if predicted == 1:\n",
        "                tp += 1\n",
        "            else:\n",
        "                fn += 1\n",
        "        elif predicted == 1:\n",
        "            fp += 1\n",
        "        else:\n",
        "            tn += 1\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "accuracy = (tp+tn)/(tp+fp+fn+tn)\n",
        "print(f\"final precision: {precision}, recall: {recall}, accuracy: {accuracy}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final precision: 1.0, recall: 0.8183856502242153, accuracy: 0.9838\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxma0RFi5-s_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86eaed59-f80c-4486-d12f-e3ba0dc408de"
      },
      "source": [
        "loader_for_ate = DataLoader(framed_test, batch_size=1)\n",
        "cumulative_diff = 0\n",
        "total = 0\n",
        "framed_5 = 0\n",
        "for X, y, f in loader_for_ate:\n",
        "    if y.item():\n",
        "        if f.item():\n",
        "            cf = unframe(X[0], 1)\n",
        "            cumulative_diff += (net1.forward(X.float().view(1, -1)).item() - net1.forward(cf.float().view(1, -1)).item())\n",
        "            framed_5 += 1\n",
        "        else:\n",
        "            cf = frame(X[0], 1)\n",
        "            cumulative_diff += (net1.forward(cf.float().view(1, -1)).item() - net1.forward(X.float().view(1, -1)).item())\n",
        "        total += 1\n",
        "\n",
        "print(f\"calculated CaCE for 'frame' concept: {cumulative_diff / total}\")\n",
        "print(f\"recall is {recall} and proportion of framed points of class is {framed_5/total}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculated CaCE for 'frame' concept: 1.0\n",
            "recall is 0.7881165919282511 and proportion of framed points of class is 0.7881165919282511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUmRDwCz87ro"
      },
      "source": [
        "We got a CaCE of 1.0 (!) for the concept of having a frame present in the image. This means that the neural network relies solely on the presence of a frame that we added around the target image, which is undesirable behavior. This also explains the precision (1.0) and recall~ =0.8~=proportion_of_framed we got in the training process, as the network predicts that only images with a frame are the correct ones, therefore never being wrong and achieving a precision of 1.0, however for the (on average) 20% of correct images which didn't have a frame added to them, the network never predicts them to be correct therefore achieving ~80% recall.\n",
        "We can see that the CaCE correctly identifies undesirable behavior of the network as it shows that it relies on our fabricated concept."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5wkO_EfGoSS"
      },
      "source": [
        "# ACE calculation & visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4fEIvJgGr13",
        "outputId": "1d5c9bed-9f03-4629-be4b-944cbf6cff41"
      },
      "source": [
        "loader_for_ace = DataLoader(framed_test, batch_size=1, shuffle=True)\n",
        "ace = torch.zeros((28,28)) # Initializing ace per pixel\n",
        "counter = 0\n",
        "for X, y, f in loader_for_ace:\n",
        "    X = X[0]\n",
        "    baseline = net1.forward(X.float().view(1, -1)).item()\n",
        "    for i in range(28):\n",
        "      for j in range(28):\n",
        "        intervened_X = torch.clone(X)\n",
        "        intervened_X[i][j] = 0\n",
        "        intervened_pred = net1.forward(intervened_X.float().view(1, -1)).item()\n",
        "        ace[i][j] += intervened_pred - baseline\n",
        "    counter += 1\n",
        "    if counter % 1000 == 0:\n",
        "      print(f'finished {counter}')\n",
        "    if counter % 3333 == 0:\n",
        "      print(ace/counter)\n",
        "ace /= counter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finished 1000\n",
            "finished 2000\n",
            "finished 3000\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.]])\n",
            "finished 4000\n",
            "finished 5000\n",
            "finished 6000\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.]])\n",
            "finished 7000\n",
            "finished 8000\n",
            "finished 9000\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0.]])\n",
            "finished 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "JVOCFlrEwMQP",
        "outputId": "92198854-62a0-4748-cf4f-b0d1d392321b"
      },
      "source": [
        "plt.imshow(ace, cmap='coolwarm', aspect='equal',interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.title(\"ACE of class neuron 5 on the pixels of decoded image\")\n",
        "plt.savefig(\"ACE of class neuron 5 on the pixels of decoded image\" , dpi=1000)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns6NrrBFXVVM"
      },
      "source": [
        "We got ACE matrix of zeroes, this means we couldn't find a causal effect of any pixels on the output. This can be explained by the in-sensitivity of ACE to concepts and also the extremality of the bias in our NN towards the concept of frame in class=5 images."
      ]
    }
  ]
}